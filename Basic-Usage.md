# Basic Usage

## Step-by-step walthrough

### Create User

### Importing Data sets

### Workflow editor

### Creating your first predictive experiment

Now that we have completed the previous steps, we are able to deepen our
knowledge by creating our first complete experiment. We will learn to use
machine learning techniques to evaluate and make predictions about the database
we loaded in the Importing Data sets step. We will build a model, based on algorithms, capable of analyzing the data, find
relationships and statistical partterns.

The process of creating a model starts with the data set statistical study. We
must know the base attributes in order to formalize what questions our model is
capable to answer.

The Iris database was used by R. Fisher in 1936 in the classic article <i> The
Use of Multiple Measurements in Taxonomic Problems</i> and can also be found in
the <i>UCL Machine Learning Repository</i>. It contains three species of
flowers of the genus Iris containing 50 samples, as well as some properties of
each flower. One species of flower is linearly separable from the other two,
while the other two are not linearly separable from each other.

As defined in [Importing Data sets](#importing-data-sets), the base consists of
the following attributes:
  * Sepal length in cm
  * Sepal width in cm
  * Petal length in cm
  * Petal width in cm
  * Class

An intial statistical analysis of the data will help us to understand the main
relationships between attributes and infer what information we can extract.
Let's use the <b> Lemonade </b> to create a workflow and some operations to
generate a data summary.

Let's create a workflow named: <b>Creating your first predictive
experiment</b>:
![create-workflow](/img/basic_usage/creating_1_predictive_final.png)
![new-workflow](/img/basic_usage/workflow_name_final.png)






